{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b9f9b1-b51b-4ea4-ab15-9b3498906efa",
   "metadata": {},
   "source": [
    "## Burstiness\n",
    "- Burstiness refers to sudden spikes in activity or usage over a short period. This can help identify periods of high resource demand.\n",
    "- High burstiness may indicate inefficiencies or unusual workload patterns.\n",
    "\n",
    "Probably the easiest way to do it is to look at <b> max-to-mean ratio:\n",
    "- Use it as a measure of variability and peak usage relative to average usage.\n",
    "- A high max-to-mean ratio might indicate significant variability and the presence of peaks well above the average.\n",
    "- A low max-to-mean ratio might indicate more consistent and stable usage.\n",
    "    \n",
    "People also use this as a threshold <b> mean + 2 * std </b>, when they explore burstiness but I'm not sure if that's the best way for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b45ffb2-1726-41a8-98f7-3aa20900d6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as PC\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead1680d-d766-4c33-83ac-9b3ebabfa7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_filepath = \"/pscratch/sd/o/ocankur/data/resource_usage_paper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f4a2159-b699-46e6-a8a5-0540fabc4bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_duration(dataframe, seconds=10):\n",
    "    # remove jobs that take less than 10 secs.\n",
    "    dataframe[\"start_time\"] = pd.to_datetime(dataframe[\"start\"], unit='s', utc=True)\n",
    "    dataframe[\"end_time\"] = pd.to_datetime(dataframe[\"end\"], unit='s', utc=True)\n",
    "    dataframe[\"duration\"] = dataframe[\"end_time\"] - dataframe[\"start_time\"]\n",
    "    dataframe = dataframe[dataframe[\"duration\"] > datetime.timedelta(0,seconds)]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fbd751e-02a6-4a7b-9da9-2e6aa9e31c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(ldms_dataframe, sacct_dataframe, metric, percentage=True):\n",
    "    \"\"\"\n",
    "    Remove jobs that take less than 10 seconds.\n",
    "    Filter out completed jobs.\n",
    "    Filter out 'nstaff' and 'nstaff_g'\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Number of LDMS data points before preprocessing: \", len(ldms_dataframe.index))\n",
    "    \n",
    "    if percentage:\n",
    "        if metric == \"mem_copy_utilization\" or metric == \"gpu_utilization\":\n",
    "            ldms_dataframe = ldms_dataframe[ldms_dataframe[metric] <= 100].copy()\n",
    "        else:\n",
    "            ldms_dataframe = ldms_dataframe[ldms_dataframe[metric] <= 1].copy()\n",
    "            ldms_dataframe.loc[:, metric] = ldms_dataframe[metric] * 100\n",
    "    \n",
    "    sacct_dataframe = get_duration(sacct_dataframe, 10)\n",
    "    \n",
    "    sacct_dataframe = sacct_dataframe[sacct_dataframe[\"Account\"] != \"nstaff_g\"]\n",
    "    sacct_dataframe = sacct_dataframe[sacct_dataframe[\"Account\"] != \"nstaff\"]\n",
    "    \n",
    "    sacct_dataframe = sacct_dataframe[sacct_dataframe[\"state\"] == \"COMPLETED\"]\n",
    "    \n",
    "    sacct_dataframe.rename(columns={'jobidraw': 'jobid'}, inplace=True)\n",
    "    merged_ldms = ldms_dataframe.merge(sacct_dataframe, on=[\"ProducerName\", \"jobid\", \"step\"])\n",
    "    \n",
    "    print(\"Number of LDMS data points after preprocessing: \", len(merged_ldms.index))\n",
    "    \n",
    "    return merged_ldms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf02602-05a7-4669-b29b-387f7a74170c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of LDMS data points before preprocessing:  116803958\n",
      "Number of LDMS data points after preprocessing:  52268361\n"
     ]
    }
   ],
   "source": [
    "df_gputil = pd.read_parquet(csv_filepath + \"/\" + \"dcgm.gpu_utilization.1692169200.1692428399.8.16_ldms.pq\")\n",
    "df_sacct_gputil = pd.read_parquet(csv_filepath + \"/\" + \"dcgm.gpu_utilization.1692169200.1692428399.8.16_saact.pq\")\n",
    "df_gputil = preprocess_data(df_gputil, df_sacct_gputil, metric=\"gpu_utilization\", percentage=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
